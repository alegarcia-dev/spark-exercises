{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ce539b-13ac-4862-99a5-8b369d9260e0",
   "metadata": {},
   "source": [
    "# Spark 101 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817ec6db-f352-4749-9d0d-aa8459864338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/19 08:59:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/19 08:59:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pydataset import data\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cff4e4-7803-4769-a45b-37bb9718fbb2",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc26970-1044-4fd7-93a9-80d3569732f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe and view schema\n",
    "df = spark.createDataFrame(pd.DataFrame(['Python', 'C++', 'C#', 'BF', 'TheOneWithTheCode'], columns = ['language']))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9163a09c-c4bf-4d66-a831-d7bcfe6b678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# print shape of the dataframe\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4890f11-7133-4ae1-9e6d-2e3c5238f2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         language|\n",
      "+-----------------+\n",
      "|           Python|\n",
      "|              C++|\n",
      "|               C#|\n",
      "|               BF|\n",
      "|TheOneWithTheCode|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0169997-4d85-4622-8ac9-9d775976dcb2",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "- Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "        The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "    For each vehicle.\n",
    "\n",
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e71d43-565a-41ed-8b44-47a3b9259f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a65bd4-3991-46c1-ae65-fee4f375dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|Vehicle Description             |\n",
      "+--------------------------------+\n",
      "|The 1999 audi a4 has a 4 engine.|\n",
      "|The 1999 audi a4 has a 4 engine.|\n",
      "|The 2008 audi a4 has a 4 engine.|\n",
      "|The 2008 audi a4 has a 4 engine.|\n",
      "|The 1999 audi a4 has a 6 engine.|\n",
      "+--------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a column in the form \"The (year) (manufacturer) (model) has a (cyl) engine.\"\n",
    "\n",
    "mpg.select(\n",
    "    F.concat(\n",
    "        F.lit('The '),\n",
    "        mpg.year,\n",
    "        F.lit(' '),\n",
    "        mpg.manufacturer,\n",
    "        F.lit(' '),\n",
    "        mpg.model,\n",
    "        F.lit(' has a '),\n",
    "        mpg.cyl,\n",
    "        F.lit(' engine.')\n",
    "    ).alias('Vehicle Description')\n",
    ").show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bdd4c34-abee-4148-a6f4-a0add8bf6c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|regexp_replace(trans, \\(\\w+\\), , 1)|\n",
      "+-----------------------------------+\n",
      "|                               auto|\n",
      "|                             manual|\n",
      "|                             manual|\n",
      "|                               auto|\n",
      "|                               auto|\n",
      "+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the text in parantheses from the trans column.\n",
    "mpg.select(F.regexp_replace('trans', r'\\(\\w+\\)', '')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56392bbc-89b9-44cf-ac2c-4598a7d29dc7",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f175d3d3-08bd-4eb5-83d3-143f8aaa5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf86dc01-4c74-4ec2-84a8-1ad4392e1abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6dd9470-434d-4839-aa12-5d54338aba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38114754098360654"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of observations that are smokers.\n",
    "df.where(df.smoker == 'Yes').count() / df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c39518-70e1-4fb7-82bc-1ccefbe4e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tip percentage column.\n",
    "df = df.withColumn('tip_percentage', df.tip / df.total_bill)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300eb15c-4d91-4ec2-94c0-265e5aaf0eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------------------+\n",
      "|   sex|smoker|avg(tip_percentage)|\n",
      "+------+------+-------------------+\n",
      "|  Male|    No| 0.1606687151291298|\n",
      "|Female|    No| 0.1569209707691836|\n",
      "|  Male|   Yes|0.15277117520248512|\n",
      "|Female|   Yes|0.18215035269941032|\n",
      "+------+------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate average tip percentage for groups of sex and smoker.\n",
    "df.groupBy('sex', 'smoker').agg(F.mean(df.tip_percentage)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78e035-893e-4916-930a-221c8663e8b6",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f500bb1c-61f9-4b1f-8e8c-2c680d6e562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5696469b-5c9e-48ed-ac32-ca1fd83ba3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data.seattle_weather())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e18a542-a483-4c60-84bf-1a35d74512fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------------------+--------+----+-------+\n",
      "|               date|precipitation|          temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+------------------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|55.040000000000006|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|             51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|             53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|             53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|48.019999999999996|   37.04| 6.1|   rain|\n",
      "+-------------------+-------------+------------------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert temperatures to fahrenheit.\n",
    "\n",
    "df = df.withColumn('temp_max', df.temp_max * 1.8 + 32).withColumn('temp_min', df.temp_min * 1.8 + 32)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82ed5857-b0ac-453a-ac02-55d377eed9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|month|avg(precipitation)|\n",
      "+-----+------------------+\n",
      "|   10|             9.675|\n",
      "+-----+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate month with most rain on average.\n",
    "\n",
    "df.withColumn('month', F.month('date'))\\\n",
    "    .where(df.weather == 'rain')\\\n",
    "    .groupBy('month')\\\n",
    "    .agg(F.mean('precipitation'))\\\n",
    "    .sort('avg(precipitation)', ascending = False).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b509766f-c875-4fc1-8d6f-e14963f1b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year|sum(wind)|\n",
      "+----+---------+\n",
      "|2012|   1244.7|\n",
      "+----+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate windiest year.\n",
    "\n",
    "df.withColumn('year', F.year('date'))\\\n",
    "    .groupBy('year')\\\n",
    "    .agg(F.sum('wind'))\\\n",
    "    .sort('sum(wind)', ascending = False).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76740332-fd37-4857-8020-809ed59eeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "+-------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate most frequent type of weather in January.\n",
    "\n",
    "df.where(F.month('date') == 1)\\\n",
    "    .groupBy('weather')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending = False).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "289f5b7b-fcee-4fab-8c60-efc8a5beef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|    avg(temp_max)|    avg(temp_min)|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "\n",
    "df.where((df.weather == 'sun')\\\n",
    "         & (F.month('date') == 7)\\\n",
    "         & ((F.year('date') == 2013)\\\n",
    "         | (F.year('date') == 2014)))\\\n",
    "    .select(F.mean('temp_max'), F.mean('temp_min')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29c2bbc6-bc11-4188-b0ef-38ec149910a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/19 10:37:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/19 10:37:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/19 10:37:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/19 10:37:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------------+\n",
      "|weather|count|          percentage|\n",
      "+-------+-----+--------------------+\n",
      "|    fog|   21| 0.22826086956521738|\n",
      "|drizzle|    5| 0.05434782608695652|\n",
      "|   rain|    2|0.021739130434782608|\n",
      "|    sun|   64|  0.6956521739130435|\n",
      "+-------+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df.where((F.year('date') == 2015) & (F.quarter('date') == 3))\\\n",
    "    .groupBy('weather')\\\n",
    "    .count()\\\n",
    "    .withColumn('percentage', F.col('count') / F.sum('count').over(Window.partitionBy())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a5c7ecc-2dae-447d-8ea2-7c095b9af102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+\n",
      "|year|avg(non_zero_precipitation)|\n",
      "+----+---------------------------+\n",
      "|2012|        0.48360655737704916|\n",
      "|2013|        0.41643835616438357|\n",
      "|2014|          0.410958904109589|\n",
      "|2015|        0.39452054794520547|\n",
      "+----+---------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "\n",
    "df.withColumn('year', F.year('date'))\\\n",
    "    .withColumn('non_zero_precipitation', (df.precipitation > 0).cast('int'))\\\n",
    "    .select('year', 'non_zero_precipitation')\\\n",
    "    .groupBy('year')\\\n",
    "    .agg(F.mean('non_zero_precipitation')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
